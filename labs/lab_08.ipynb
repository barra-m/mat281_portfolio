{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio N°08\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1'></a>\n",
    "## I.- Problema 01\n",
    "\n",
    "\n",
    "<img src=\"https://www.cardrates.com/wp-content/uploads/2020/08/shutterstock_576998230.jpg?1\" width=\"480\" height=\"360\" align=\"center\"/>\n",
    "\n",
    "\n",
    "El conjunto de datos se denomina `creditcard.csv` y consta de varias columnas con información acerca del fraude de tarjetas de crédito, en donde la columna **Class** corresponde a: 0 si no es un fraude y 1 si es un fraude.\n",
    "\n",
    "En este ejercicio se trabajará el problemas de  clases desbalancedas. Veamos las primeras cinco filas dle conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar datos\n",
    "df = pd.read_csv(os.path.join(\"data\",\"creditcard.csv\"), sep=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos el total de fraudes respecto a los casos que nos son fraudes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular proporciones\n",
    "df_count = pd.DataFrame()\n",
    "df_count[\"fraude\"] =[\"no\",\"si\"]\n",
    "df_count[\"total\"] = df[\"Class\"].value_counts() \n",
    "df_count[\"porcentaje\"] = 100*df_count[\"total\"] /df_count[\"total\"] .sum()\n",
    "\n",
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que menos del 1% corresponde a registros frudulentos. La pregunta que surgen son:\n",
    "\n",
    "* ¿ Cómo deben ser el conjunto de entrenamiento y de testeo?\n",
    "* ¿ Qué modelos ocupar?\n",
    "* ¿ Qué métricas ocupar?\n",
    "\n",
    "Por ejemplo, analicemos el modelos de regresión logística y apliquemos el procedimiento estándar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos \n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "\n",
    "# Creando el modelo\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    " \n",
    "# predecir\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# calcular accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general el modelo tiene un **accuracy** del 99,9%, es decir, un podría suponer que el modelo predice casi perfectamente, pero eso esta lejos de ser así.  Para ver por qué es necesario seguir los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cambiar la métrica de rendimiento\n",
    "\n",
    "El primer paso es comparar con distintas métricas, para eso ocupemos las 4 métricas clásicas abordadas en el curso:\n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* f-score\n",
    "\n",
    "En este punto deberá poner las métricas correspondientes y comentar sus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(lr.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_test, lr_pred))\n",
    "print('recall:     ',recall_score(y_test, lr_pred))\n",
    "print('precision:  ',precision_score(y_test, lr_pred))\n",
    "print('f-score:    ',f1_score(y_test, lr_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz calculada por **confusion_matrix** difiere de la vista en clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "mc = confusion_matrix(y_true,y_pred)\n",
    "print(f'FP',mc[0,0])\n",
    "print(f'FN',mc[1,0])\n",
    "print(f'TN',mc[0,1])\n",
    "print(f'TP',mc[1,1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(mc, display_labels = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, en realidad se tiene que la matriz de confusión dada por la función **confusion_matrix** está rotada en $\\pi$ grados con respecto a la vista en clases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/confusion_matrix.png\" width=\"200\" height=\"200\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una alta exactitud (**accuracy**) en el modelo ya que la cantidad de fraudes del conjunto de datos es más bajo en comparación a la muestra, por lo tanto se obtuvieron mayor cantidad proporcional de verdaderos positivos y negativos al comparar con verdaderos y errores (explicado previamente por el Profesor en el enunciado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener mayor precisión que exhaustividad (**recall**), se deduce que hay una mayor tasa de falsos positivos a verdaderos positivos que viceversa. Esto sale directamente de la matriz de confusión en la cual el número de falsos negativos duplica a los falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comparará el valor **F-score** obtenido con el de otros modelos, aunque a priori, 0.8 es más cercano a 1 que a 0 por lo que se comporta de buena manera. Este indicador corresponde al promedio armónico entre precisión y exhaustividad por lo que, en teoría, ya se realizó el análisis de esta métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar curva roc\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# calcular score AUC\n",
    "\n",
    "probs = lr.predict_proba(X_test) # predecir probabilidades para X_test\n",
    "probs_tp = probs[:, 1] # mantener solo las probabilidades de la clase positiva \n",
    "       \n",
    "auc = roc_auc_score(y_test, probs_tp)  # calcular score AUC \n",
    "\n",
    "print('AUC: %.2f' % auc)\n",
    "\n",
    "# calcular curva ROC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs_tp) # obtener curva ROC\n",
    "lrplot = plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cambiar algoritmo\n",
    "\n",
    "El segundo paso es comparar con distintos modelos. Debe tener en cuenta que el modelo ocupado resuelva el problema supervisado de clasificación.\n",
    "\n",
    "En este punto deberá ajustar un modelo de **random forest**, aplicar las métricas y comparar con el modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "# datos\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "# crear modelo\n",
    "rfc = RandomForestClassifier(max_depth=5, n_estimators=500, max_features=1).fit(X_train, y_train) #algoritmo Random Forest\n",
    "\n",
    "# predecir\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "#rfc =  None # algoritmo random forest\n",
    "\n",
    "# calcular precision\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(rfc.predict(X_test)) # predicciones con random forest\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exactitud al usar el modelo **random forest** decrece levemente (0.1%) en comparación a la dada en **logistic regression** ya que disminuyen los verdaderos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los falsos negativos aumentaron lo que redujo la exhaustividad aproximadamente en un 15%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo predijo cero falsos positivos por lo que la precisión es perfecta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De este modo, el **F-score** disminuye marginalmente al comparar el obtenido para regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular score AUC\n",
    "\n",
    "probs = rfc.predict_proba(X_test) # predecir probabilidades para X_test\n",
    "probs_tp = probs[:, 1] # mantener solo las probabilidades de la clase positiva \n",
    "       \n",
    "auc = roc_auc_score(y_test, probs_tp)  # calcular score AUC \n",
    "\n",
    "print('AUC: %.2f' % auc)\n",
    "\n",
    "# calcular curva ROC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs_tp) # obtener curva ROC\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Técnicas de remuestreo: sobremuestreo de clase minoritaria\n",
    "\n",
    "El tercer paso es ocupar ténicas de remuestreo, pero sobre la clase minoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase minoritaria a la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# concatenar el conjunto de entrenamiento\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separar las clases\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]\n",
    "\n",
    "# remuestrear  clase minoritaria\n",
    "fraud_upsampled = resample(fraud,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "# recombinar resultados\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "# chequear el número de elementos por clases\n",
    "upsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrenamiento sobre-balanceados\n",
    "y_train = upsampled.Class\n",
    "X_train = upsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = LogisticRegression(solver='liblinear').fit(X_train, y_train) # algoritmo de regresion logistica\n",
    "\n",
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(upsampled.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtiene leves cambios en la exactitud al realizar remuestro (se reduce en un 2%).\n",
    "Aumenta el número de falsos negativos en orden de magnitud 1 y disminuyen los verdaderos negativos, esto produce un aumento de la exhaustividad pero reduce categóricamente la precisión y en consecuencia el **F-Score** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular score AUC\n",
    "\n",
    "probs = upsampled.predict_proba(X_test) # predecir probabilidades para X_test\n",
    "probs_tp = probs[:, 1] # mantener solo las probabilidades de la clase positiva \n",
    "       \n",
    "auc = roc_auc_score(y_test, probs_tp)  # calcular score AUC \n",
    "\n",
    "print('AUC: %.2f' % auc)\n",
    "\n",
    "# calcular curva ROC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs_tp) # obtener curva ROC\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Técnicas de remuestreo - Ejemplo de clase mayoritaria\n",
    "\n",
    "El cuarto paso es ocupar ténicas de remuestreo, pero sobre la clase mayoritaria. Esto significa que mediantes ténicas de remuestreo trataremos de equiparar el número de elementos de la clase mayoritaria  a la clase minoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remuestreo clase mayoritaria\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# recombinar resultados\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# chequear el número de elementos por clases\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrenamiento sub-balanceados\n",
    "\n",
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ocupando estos nuevos conjunto de entrenamientos, vuelva a aplicar el modelos de regresión logística y calcule las correspondientes métricas. Además, justifique las ventajas y desventjas de este procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train) # algoritmo de regresion logistica # modelo de regresi+on logística\n",
    "\n",
    "# metrics\n",
    "\n",
    "y_true =  list(y_test)\n",
    "y_pred = list(undersampled.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "print('\\nMetricas:\\n ')\n",
    "print('accuracy:   ',accuracy_score(y_true,y_pred))\n",
    "print('recall:     ',recall_score(y_true,y_pred))\n",
    "print('precision:  ',precision_score(y_true,y_pred))\n",
    "print('f-score:    ',f1_score(y_true,y_pred))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que con el sobremuestreo, el número de falsos positivos aumenta en orden de magnitud 1 con respecto al análisis sin muestreo y los falsos negativos se reducen a la mitad, reduciendo la precisión  y aumentando la exhaustividad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las métricas son similares a las de sobremuestreo salvo exhaustividad que presenta una pequeña baja porcentual de 4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular score AUC\n",
    "\n",
    "probs = undersampled.predict_proba(X_test) # predecir probabilidades para X_test\n",
    "probs_tp = probs[:, 1] # mantener solo las probabilidades de la clase positiva \n",
    "       \n",
    "auc = roc_auc_score(y_test, probs_tp)  # calcular score AUC \n",
    "\n",
    "print('AUC: %.2f' % auc)\n",
    "\n",
    "# calcular curva ROC\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs_tp) # obtener curva ROC\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusiones\n",
    "\n",
    "Para finalizar el laboratorio, debe realizar un análisis comparativo con los disintos resultados obtenidos  en los pasos 1-4. Saque sus propias conclusiones del caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos difieren, en particular se obtiene una mayor precisión al utilizar **random forest** en comparación con **regresión logística** con o sin remuestreo. Al realizar muestreos se incrementa la exhaustividad al realizar predicciones pero se decrementa la exactitud bruscamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, al comparar ambos remuestreos en la regresión logística, se tiene una mayor cantidad de falsos positivos y menor cantidad de falsos negativos al realizar un sobremuestreo en comparación a hacer un remuestreo sobre la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde las curvas y puntajes ROC, se puede inferir que **random_forest** es un modelo técnicamente mas adecuado para predecir fraudes, aunque marginalmente: **random forest**  obtuvo un puntaje de 0.96 mientras que **regresion logistica** obtuvo 0.92."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede recomendar utilizar un modelo adecuado dependiendo si se desea maximizar precisión o exhaustividad, o en su defecto utilizar un modelo con métricas mas balanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
