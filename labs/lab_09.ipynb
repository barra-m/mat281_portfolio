{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio N°03\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1'></a>\n",
    "## I.- Problema 01\n",
    "\n",
    "\n",
    "<img src=\"https://freedesignfile.com/upload/2013/06/Car-logos-1.jpg\" width=\"360\" height=\"360\" align=\"center\"/>\n",
    "\n",
    "\n",
    "El conjunto de datos se denomina `vehiculos_procesado_con_grupos.csv`, el cual contine algunas de las características más importante de un vehículo.\n",
    "\n",
    "En este ejercicio se tiene como objetivo, es poder clasificar los distintos vehículos basados en las cracterísticas que se presentan a continuación. La dificultad de este ejercicio radíca en que ahora tenemos variables numéricas y variables categóricas.\n",
    "\n",
    "Lo primero será cargar el conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar datos\n",
    "df = pd.read_csv(os.path.join(\"data\",\"vehiculos_procesado_con_grupos.csv\"), sep=\",\")\\\n",
    "       .drop(\n",
    "            [\"fabricante\", \n",
    "             \"modelo\",\n",
    "             \"transmision\", \n",
    "             \"traccion\", \n",
    "             \"clase\", \n",
    "             \"combustible\",\n",
    "             \"consumo\"], \n",
    "    \n",
    "          axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, no solo se tienen datos numéricos, sino que también categóricos. Además, tenemos problemas de datos **vacíos (Nan)**. Así que para resolver este problema, seguiremos varios pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Normalizar datos\n",
    "\n",
    "1.- Cree un conjunto de datos con las variables numéricas, además, para cada dato vacía, rellene con el promedio asociado a esa columna. Finalmente, normalize los datos mediante el procesamiento **MinMaxScaler** de **sklearn**.\n",
    "\n",
    "2.-  Cree un conjunto de datos con las variables categóricas , además, transforme de variables categoricas a numericas ocupando el comando **get_dummies** de pandas ([referencia](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)). Explique a grande rasgo como se realiza la codificación de variables numéricas a categóricas.\n",
    "\n",
    "3.- Junte ambos dataset en uno, llamado **df_procesado**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# crear dataframe conteninendo solo variables numericas\n",
    "# notar que convenientemente, las variables no numéricas contienen el string 'tipo'  \n",
    "df_num = df.drop(df.filter(regex='tipo'), axis=1)\n",
    "display(df_num.head())\n",
    "print(\"Cantidad de datos nulos: \")\n",
    "df_num.isnull().sum(axis = 0) #chequear cantidad de NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rellenar celdas vacía con el promedio \n",
    "columnas = df_num.columns\n",
    "[df_num[col].fillna(value = df[col].mean(), inplace = True) for col in columnas]\n",
    "print(\"Cantidad de datos nulos: \")\n",
    "df_num.isnull().sum(axis = 0) #rechequear si hay datos NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizacion usando MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "columns = df_num.columns\n",
    "df_num[columns] = scaler.fit_transform(df[columns])\n",
    "display(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se inspecciona para ver si funciono mediante scatterplot 2D en dos columnas\n",
    "ax = sns.scatterplot(data = df_num, x = \"desplazamiento\", y = \"cilindros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "# crear conjunto con solo variables categóricas\n",
    "df_cat = df.filter(regex='tipo')\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usar get_dummie para transformar a variable numéricas \n",
    "df_cat = pd.get_dummies(df_cat)\n",
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función **get_dummies** básicamente toma todas las entradas **únicas** de cada columna de valores categóricos del dataframe original y las convierte en nuevas columnas.  En cada entrada de las filas se va rellenando con un 1 si es que el dato pertenece a la categoría ahora dada por una columna y con 0 en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# juntar datos númericos y datos dummyficados\n",
    "df_procesado = pd.concat([df_num,df_cat], axis =1, sort = False).fillna(0)\n",
    "df_procesado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Realizar ajuste mediante kmeans\n",
    "\n",
    "Una vez depurado el conjunto de datos, es momento de aplicar el algoritmo de **kmeans**.\n",
    "\n",
    "1. Ajuste el modelo de **kmeans** sobre el conjunto de datos, con un total de **8 clusters**.\n",
    "2. Asociar a cada individuo el correspondiente cluster y calcular valor de los centroides de cada cluster.\n",
    "3. Realizar un resumen de las principales cualidades de cada cluster. Para  esto debe calcular (para cluster) las siguientes medidas de resumen:\n",
    "    * Valor promedio de las variables numérica\n",
    "    * Moda para las variables numericas\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "kmeans = KMeans(n_clusters=8)\n",
    "kmeans.fit(df_procesado)\n",
    "\n",
    "centroids = kmeans.cluster_centers_ # centros\n",
    "clusters = kmeans.labels_ #clusters\n",
    "\n",
    "centroids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "df_procesado[\"cluster\"] = clusters\n",
    "df_procesado[\"cluster\"] = df_procesado[\"cluster\"].astype('category')\n",
    "display(df_procesado.head())\n",
    "centroids_df = pd.DataFrame(centroids, columns = df_procesado.columns.drop('cluster'))\n",
    "centroids_df[\"cluster\"] = np.arange(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tanteo en 2D para ver si se alcanzan a divisar los clusters para dos columnas\n",
    "fig, ax = plt.subplots(figsize=(11,8.5))\n",
    "sns.scatterplot(\n",
    "        data = df_procesado,\n",
    "        x = \"consumo_litros_milla\",\n",
    "        y = \"co2\", \n",
    "        hue = \"cluster\",\n",
    "        legend = 'full',\n",
    "        palette =\"Set2\"\n",
    "        )\n",
    "\n",
    "g = sns.scatterplot(\n",
    "        x = \"consumo_litros_milla\",\n",
    "        y = \"co2\",\n",
    "        s=100, color = \"black\", marker = \"x\",\n",
    "        data = centroids_df\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "df_aux = df_procesado.drop(df_procesado.filter(regex='_tipo'), axis = 1)\n",
    "medias = df_aux.groupby('cluster').mean()\n",
    "moda = df_aux.groupby('cluster').apply(lambda x: x.mode()).drop('cluster', axis = 1)\n",
    "display(medias)\n",
    "display(moda)\n",
    "print(\"***Recordar que estos datos han sido normalizados según el critero MinMaxScale***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Elegir Número de cluster\n",
    "\n",
    "Estime mediante la **regla del codo**, el número de cluster apropiados para el caso.\n",
    "Para efectos prácticos, eliga la siguiente secuencia como número de clusters a comparar:\n",
    "\n",
    "$$[5, 10, 20, 30, 50, 75, 100, 200, 300]$$\n",
    "\n",
    "Una ve realizado el gráfico, saque sus propias conclusiones del caso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regla del codo\n",
    "# advertencia: se requieren moderadamente altos recursos computacionales al correr esta celda (un par de minutos)\n",
    "\n",
    "Nc = [5,10,20,30,50,75,100,200,300]\n",
    "kmeans = [KMeans(n_clusters = i) for i in Nc]\n",
    "score = [kmeans[i].fit(df_procesado).inertia_ for i in range(len(kmeans))]\n",
    "\n",
    "df_Elbow = pd.DataFrame({'Number of Clusters':Nc,\n",
    "                        'Score':score})\n",
    "df_Elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar los datos etiquetados con k-means\n",
    "fix, ax = plt.subplots(figsize = (11, 8.5))\n",
    "plt.title('Elbow Curve')\n",
    "sns.lineplot(x = 'Number of Clusters', y='Score', data=df_Elbow)\n",
    "g = sns.scatterplot(x = 'Number of Clusters', y='Score', data=df_Elbow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor diferencia de pendientes se observa entre la pendientes desde 5 a 10 clusters y la de 10 a 20 clusters, por lo que según el criterio visto en clases el número óptimo de clústers sería 10. \n",
    "\n",
    "Se podrían haber tomado los años de los vehículos como datos categóticos en vez de numéricos y ver como cambian los clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.- Problema 02\n",
    "\n",
    "<img src=\"https://live.staticflickr.com/7866/47075467621_85ab810139_c.jpg\" align=\"center\"/>\n",
    "\n",
    "Para el conjunto de datos de **Iris**, se pide realizar una reducción de dimensionalidad ocupando las técnicas de PCA y TSNE (vistas en clases). \n",
    "\n",
    "El objetivo es aplicar ambos algoritmos de la siguiente manera:\n",
    "\n",
    "* Análisis detallado algoritma PCA (tablas, gráficos, etc.)\n",
    "* Análisis detallado algoritma TSNE (tablas, gráficos, etc.)\n",
    "* Comparar ambos algoritmos (conclusiones del caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from time import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_iris()\n",
    "features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "target = 'species'\n",
    "\n",
    "iris = pd.DataFrame(\n",
    "    dataset.data,\n",
    "    columns=features)\n",
    "\n",
    "iris[target] = dataset.target\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "scaler = StandardScaler() #reescalado según la normal estándar ie z = (x - u) / s con u, s media y std de la muestra de entrenamiento\n",
    "\n",
    "#separación de target y datos\n",
    "X = iris.drop(columns='species') \n",
    "y = iris['species']\n",
    "#obtención de 2 componentes principales vía método PCA\n",
    "embedding = PCA(n_components=2) \n",
    "X_transform = embedding.fit_transform(X)\n",
    "\n",
    "df_pca = pd.DataFrame(X_transform, columns = ['Score1', 'Score2']) #empacar a dataframe\n",
    "df_pca['species'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Iris PCA\n",
    "\n",
    "# estilo del grafico de dispersion\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "sns.lmplot(x='Score1',\n",
    "          y='Score2',\n",
    "          data = df_pca,  \n",
    "          fit_reg=False,\n",
    "          legend=True,\n",
    "          height=9,\n",
    "          hue='species',\n",
    "          scatter_kws = {\"s\":200, \"alpha\":0.3} \n",
    "          )\n",
    "plt.title('PCA Results: Iris', weight='bold').set_fontsize('14')\n",
    "plt.xlabel('PC1', weight='bold').set_fontsize('10')\n",
    "plt.ylabel('PC2', weight='bold').set_fontsize('10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico de las dos componentes principales desde el método **PCA**  se observa que distingue correctamente la especie 0 del resto, mientras que las otras especies presentan intersección, aunque la mayor parte de los datos son distinguidos correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tSNE\n",
    "scaler = StandardScaler() #reescalado normal estandar al igual que en PCA\n",
    "#separar target de datos\n",
    "X = iris.drop(columns='species')\n",
    "y = iris['species']\n",
    "#obtención de 2 componentes principales mediante tSNE    \n",
    "embedding = TSNE(n_components=2)\n",
    "X_transform = embedding.fit_transform(X)\n",
    "    \n",
    "df_tsne = pd.DataFrame(X_transform,columns = ['_DIM_1_','_DIM_2_'])\n",
    "df_tsne['species'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Digits t-SNE\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "sns.lmplot(x='_DIM_1_',\n",
    "           y='_DIM_2_',\n",
    "           data=df_tsne,\n",
    "           fit_reg=False,\n",
    "           legend=True,\n",
    "           height=9,\n",
    "           hue='species',\n",
    "           scatter_kws={\"s\":200, \"alpha\":0.3})\n",
    "\n",
    "plt.title('t-SNE Results: Digits', weight='bold').set_fontsize('14')\n",
    "plt.xlabel('Dimension 1', weight='bold').set_fontsize('10')\n",
    "plt.ylabel('Dimension 2', weight='bold').set_fontsize('10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en **PCA**, el método **tSNE** distingue correctamente la especie 0. Hay algunos datos clasificados incorrectamente ya que hay una intersección de los clúster para especies 1 y 2, pero en general es bastante efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos métodos distinguen apropiadamente la especie 0 del resto, sin embargo las especies 1 y 2 no son separadas totalmente. Se realizaron varias iteraciones, **tSNE** siempre agrupa al menos 4 datos en la intersección de las especies 1 y 2 no pudiendo ver claramente una distinción entre este subcojunto de datos. Por otro lado de los gráficos de **PCA**, se puede imaginar una suerte de recta separando las especies pero no totalmente.\n",
    "\n",
    "En resumen, ambos métodos clasifican con similar efectividad por lo es viable reducir la dimensionalidad del problema, se recomienda **PCA** ya que al correr varias veces los modelos este presenta mayor efectividad al clasificar especies (visualmente) al menos para este conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
