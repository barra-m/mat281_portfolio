{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAT281 - Laboratorio N°11\n",
    "\n",
    "<a id='p1'></a>\n",
    "## I.- Problema 01\n",
    "\n",
    "Lista de actos delictivos registrados por el Service de police de la Ville de Montréal (SPVM).\n",
    "\n",
    "\n",
    "<img src=\"http://henriquecapriles.com/wp-content/uploads/2017/02/femina_detenida-1080x675.jpg\" width=\"480\" height=\"360\" align=\"center\"/>\n",
    "\n",
    "El conjunto de datos en estudio `interventionscitoyendo.csv` corresponde a  todos los delitos entre 2015 y agosto de 2020en Montreal. Cada delito está asociado en grandes categorías, y hay información sobre la ubicación, el momento del día, etc.\n",
    "\n",
    "> **Nota**: Para más información seguir el siguiente el [link](https://donnees.montreal.ca/ville-de-montreal/actes-criminels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerias \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from metrics_regression import *\n",
    "\n",
    "\n",
    "# graficos incrustados\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "# parametros esteticos de seaborn\n",
    "sns.set_palette(\"deep\", desat=.6)\n",
    "sns.set_context(rc={\"figure.figsize\": (12, 4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "validate_categorie = [\n",
    "  'Introduction', 'Méfait','Vol dans / sur véhicule à moteur', 'Vol de véhicule à moteur',\n",
    "]\n",
    "\n",
    "df = pd.read_csv(os.path.join(\"data\",\"interventionscitoyendo.csv\"), sep=\",\", encoding='latin-1')\n",
    "df.columns = df.columns.str.lower()\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "df = df.loc[lambda x: x['categorie'].isin(validate_categorie)]\n",
    "df = df.sort_values(['categorie','date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como tenemos muchos datos por categoría a nivel de día, agruparemos a nivel de **semanas** y separaremos cada serie temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date','pdq']\n",
    "y_s1 = df.loc[lambda x: x.categorie == validate_categorie[0] ][cols].set_index('date').resample('W').mean()\n",
    "y_s2 = df.loc[lambda x: x.categorie == validate_categorie[1] ][cols].set_index('date').resample('W').mean()\n",
    "y_s3 = df.loc[lambda x: x.categorie == validate_categorie[2] ][cols].set_index('date').resample('W').mean()\n",
    "y_s4 = df.loc[lambda x: x.categorie == validate_categorie[3] ][cols].set_index('date').resample('W').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este laboratorio es poder realizar un análisis completo del conjunto de datos en estudio, para eso debe responder las siguientes preguntas:\n",
    "\n",
    "1. Realizar un gráfico para cada serie temporal $y\\_{si}, i =1,2,3,4$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_s1.plot(figsize=(15,3), color = 'r')\n",
    "y_s2.plot(figsize=(15,3), color = 'r')\n",
    "y_s3.plot(figsize=(15,3), color = 'r')\n",
    "y_s4.plot(figsize=(15,3), color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Escoger alguna serie temporal $y\\_{si}, i =1,2,3,4$. Luego:\n",
    "\n",
    "* Realice un análisis exploratorio de la serie temporal escogida\n",
    "* Aplicar el modelo de pronóstico $SARIMA(p,d,q)x(P,D,Q,S)$, probando varias configuraciones de los hiperparámetros. Encuentre la mejor configuración. Concluya.\n",
    "* Para el mejor modelo encontrado, verificar si el residuo corresponde a un ruido blanco.\n",
    "\n",
    "> **Hint**: Tome como `target_date` =  '2021-01-01'. Recuerde considerar que su columna de valores se llama `pdq`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se elige y_s4 \n",
    "y = y_s4\n",
    "display(y.head())\n",
    "display(y.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "sns.boxplot(y.index.year, y.pdq, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "sns.boxplot(y.index.month, y.pdq, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creando clase SarimaModels\n",
    "\n",
    "class SarimaModels:\n",
    "    def __init__(self,params):\n",
    "\n",
    "        self.params = params\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def name_model(self):\n",
    "        return f\"SARIMA_{self.params[0]}X{self.params[1]}\".replace(' ','')\n",
    "    \n",
    "    @staticmethod\n",
    "    def test_train_model(y,date):\n",
    "        mask_ds = y.index < date\n",
    "\n",
    "        y_train = y[mask_ds]\n",
    "        y_test = y[~mask_ds]        \n",
    "        \n",
    "        return y_train, y_test\n",
    "    \n",
    "    def fit_model(self,y,date):\n",
    "        y_train, y_test = self.test_train_model(y,date )\n",
    "        model = SARIMAX(y_train,\n",
    "                        order=self.params[0],\n",
    "                        seasonal_order=self.params[1],\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        \n",
    "        model_fit = model.fit(disp=0)\n",
    "\n",
    "        return model_fit\n",
    "    \n",
    "    def df_testig(self,y,date):\n",
    "        y_train, y_test = self.test_train_model(y,date )\n",
    "        model = SARIMAX(y_train,\n",
    "                        order=self.params[0],\n",
    "                        seasonal_order=self.params[1],\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False)\n",
    "        \n",
    "        model_fit = model.fit(disp=0)\n",
    "        \n",
    "        start_index = y_test.index.min()\n",
    "        end_index = y_test.index.max()\n",
    "\n",
    "        preds = model_fit.get_prediction(start=start_index,end=end_index, dynamic=False)\n",
    "        df_temp = pd.DataFrame(\n",
    "            {\n",
    "                'y':y_test['pdq'],\n",
    "                'yhat': preds.predicted_mean\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return df_temp\n",
    "    \n",
    "    def metrics(self,y,date):\n",
    "        df_temp = self.df_testig(y,date)\n",
    "        df_metrics = summary_metrics(df_temp)\n",
    "        df_metrics['model'] = self.name_model\n",
    "        \n",
    "        return df_metrics\n",
    "\n",
    "# definir parametros \n",
    "\n",
    "import itertools\n",
    "\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "\n",
    "params = list(itertools.product(pdq,seasonal_pdq))\n",
    "target_date = '2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se procede a usar SARIMA(...)\n",
    "target_date = '2021-01-01'\n",
    "\n",
    "# crear conjuntos de entrenamiento y testeo\n",
    "mask_ds = y.index < target_date\n",
    "\n",
    "y_train = y[mask_ds]\n",
    "y_test = y[~mask_ds]\n",
    "\n",
    "# graficar\n",
    "y_train['pdq'].plot()\n",
    "y_test['pdq'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterar sobre distintos escenarios, es decir distintos parametros para SARIMA\n",
    "\n",
    "frames = []\n",
    "for param in params:\n",
    "    try:\n",
    "        sarima_model = SarimaModels(param)\n",
    "        df_metrics = sarima_model.metrics(y,target_date)\n",
    "        frames.append(df_metrics)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_result = pd.concat(frames)\n",
    "df_metrics_result.sort_values(['mae','mape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros que lograron menores **mae** y **mape** son **S A R I M A (1,1,0)X(1,0,1,12)** y **S A R I M A (0,1,0)X(1,1,0,12)** y serán los que se ocuparan para ajustar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar \n",
    "# ajustar mejor modelo\n",
    "\n",
    "param = [(1,1,0),(1,1,0,12)]\n",
    "sarima_model =  SarimaModels(param)\n",
    "model_fit = sarima_model.fit_model(y,target_date)\n",
    "best_model = sarima_model.df_testig(y,target_date)\n",
    "best_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar\n",
    "\n",
    "preds = best_model['yhat']\n",
    "ax = y['2019':].plot(label='observed')\n",
    "preds.plot(ax=ax, label='Forecast', alpha=.7, figsize=(14, 7))\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('pdq')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar \n",
    "# ajustar mejor modelo\n",
    "\n",
    "param = [(0,1,0),(1,1,0,12)]\n",
    "sarima_model =  SarimaModels(param)\n",
    "model_fit = sarima_model.fit_model(y,target_date)\n",
    "best_model = sarima_model.df_testig(y,target_date)\n",
    "best_model.head()\n",
    "# graficar\n",
    "\n",
    "preds = best_model['yhat']\n",
    "ax = y['2019':].plot(label='observed') # se grafica desde el 2019 para observar mas claramente la forma de la serie teorica\n",
    "preds.plot(ax=ax, label='Forecast', alpha=.7, figsize=(14, 7))\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('pdq')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los parámetros **S A R I M A (1,1,0)X(1,0,1,12)** no se ajusta tan apropiadamente a los datos aunque si sigue la tendencia sinusoidal decreciente que tiene la serie en el año 2021. El modelo para los parámetros **S A R I M A (0,1,0)X(1,1,0,12)** parece ajustarse mejor, se le da preferencia a modelo con estos últimos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errores\n",
    "model_fit.plot_diagnostics(figsize=(16,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del gráfico de la **residual estándarizada**, se nota que la serie es estacionaria, podría ser ruido blanco.\n",
    "\n",
    "Desde el **histograma mas densidad estimada**, la distribución del error se parece a la distribución normal (0,1). Esto da mas pistas para asumir que la serie puede ser ruido blanco.\n",
    "\n",
    "Para el scatter de **Quantiles de la muestra vs Quantiles teóricos** se aprecia una tendencia lineal por lo que las distribuciones de muestra y prueba se parecen.\n",
    "\n",
    "En el **correlograma** no se entendió muy bien como leer este tipo de gráficos, pero se deduce que si los valores no tienden a 1 o -1 en el eje de las ordenadas, al parecer no hay correlación entre las variables, es decir serían independientes entre sí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
